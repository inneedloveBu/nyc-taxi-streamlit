# create_unified_output.py
import pandas as pd
import json
from pathlib import Path
import shutil

def create_unified_output():
    """åˆ›å»ºç»Ÿä¸€çš„è¾“å‡ºç»“æ„ä¾›app.pyä½¿ç”¨"""
    project_root = Path(__file__).parent
    
    # ç›®æ ‡ç»Ÿä¸€ç›®å½•
    unified_dir = project_root / "output" / "unified"
    unified_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ” æœç´¢åˆ†æç»“æœ...")
    
    # æœç´¢æ‰€æœ‰å¯èƒ½çš„è¾“å‡º
    found_data = []
    
    for subdir in ["pandas", "spark_simple", "spark_advanced"]:
        source_dir = project_root / "output" / subdir
        if source_dir.exists():
            csv_files = list(source_dir.glob("*.csv"))
            if csv_files:
                found_data.append({
                    "dir": subdir,
                    "csv_count": len(csv_files),
                    "files": csv_files
                })
                print(f"  âœ“ æ‰¾åˆ° {subdir}: {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    if not found_data:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•åˆ†æç»“æœ")
        return False
    
    # é€‰æ‹©æ•°æ®æœ€å¤šçš„æº
    found_data.sort(key=lambda x: x["csv_count"], reverse=True)
    source_info = found_data[0]
    source_dir = project_root / "output" / source_info["dir"]
    
    print(f"ğŸ“‚ ä½¿ç”¨ {source_info['dir']} ä½œä¸ºæ•°æ®æº")
    
    # å¤åˆ¶/é‡å‘½åCSVæ–‡ä»¶åˆ°ç»Ÿä¸€ç›®å½•
    for csv_file in source_info["files"]:
        dest_file = unified_dir / csv_file.name
        shutil.copy2(csv_file, dest_file)
        print(f"  ğŸ“„ å¤åˆ¶: {csv_file.name}")
    
    # åˆ›å»ºç»Ÿä¸€çš„æŠ¥å‘Šæ–‡ä»¶
    report_data = {
        "source": source_info["dir"],
        "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
        "file_count": len(source_info["files"]),
        "files": [f.name for f in source_info["files"]]
    }
    
    # ä¿å­˜ä¸ºJSON
    report_path = unified_dir / "analysis_report.json"
    with open(report_path, 'w') as f:
        json.dump(report_data, f, indent=2)
    
    print(f"ğŸ“ åˆ›å»ºæŠ¥å‘Š: {report_path}")
    
    # ä¹Ÿåˆ›å»ºæ–‡æœ¬æŠ¥å‘Š
    txt_report = f"""æ•°æ®åˆ†ææŠ¥å‘Š
==============

æ•°æ®æº: {source_info['dir']}
ç”Ÿæˆæ—¶é—´: {report_data['timestamp']}
æ–‡ä»¶æ•°é‡: {len(source_info['files'])}

æ–‡ä»¶åˆ—è¡¨:
"""
    for i, file_name in enumerate(report_data["files"], 1):
        file_path = source_dir / file_name
        if file_path.exists():
            file_size = file_path.stat().st_size / 1024  # KB
            txt_report += f"{i}. {file_name} ({file_size:.1f} KB)\n"
    
    txt_report_path = unified_dir / "report.txt"
    with open(txt_report_path, 'w') as f:
        f.write(txt_report)
    
    print(f"ğŸ“ åˆ›å»ºæ–‡æœ¬æŠ¥å‘Š: {txt_report_path}")
    
    # æ˜¾ç¤ºæ–‡ä»¶ç»Ÿè®¡
    print("\nğŸ“Š ç»Ÿä¸€è¾“å‡ºç»Ÿè®¡:")
    for file in unified_dir.iterdir():
        if file.is_file():
            size_kb = file.stat().st_size / 1024
            print(f"  {file.name:30} {size_kb:6.1f} KB")
    
    print(f"\nâœ… ç»Ÿä¸€è¾“å‡ºåˆ›å»ºå®Œæˆ: {unified_dir}")
    return True

if __name__ == "__main__":
    create_unified_output()